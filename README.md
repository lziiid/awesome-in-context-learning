# Awesome In Context Learning [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

<p align="center">
  <img width="250" src="https://camo.githubusercontent.com/1131548cf666e1150ebd2a52f44776d539f06324/68747470733a2f2f63646e2e7261776769742e636f6d2f73696e647265736f726875732f617765736f6d652f6d61737465722f6d656469612f6c6f676f2e737667" "Awesome!">
</p>

A curated list of in-context-learning, including classic and up-to-date papers. This project will be constantly updated and improved.

**Keyword Explaination**

![](https://img.shields.io/badge/-classic-red): Classic papers in the field for those who want a quick overview of the field.

## Content
- [Papers](#papers)
  * [ICL in vision](#icl-in-vision)
    + [CoT in vision](#cot-in-vision)
  * [Theoretical analysis](#theoretical-analysis)
  * [Chain of thoughts](#chain-of-thoughts)
    + [Theoretical analysis of CoT](#theoretical-analysis-of-cot)
- [Contribution](#contribution)




## Papers

### ICL in vision
- **MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action**
(2023.03.20) [[pdf]](https://arxiv.org/abs/2303.11381) <br>

- **Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models**
(2023.03.08) [[pdf]](https://arxiv.org/abs/2303.04671) <br>

- **Multimodal Chain-of-Thought Reasoning in Language Models**
(2023.01.17) [[pdf]](https://arxiv.org/abs/2302.00923) <br>

- **Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language**
(2022.04.01) [[pdf]](https://arxiv.org/abs/2204.00598) ![](https://img.shields.io/badge/-ICLR%202023-lightgrey) <br> 

- **Multimodal Few-Shot Learning with Frozen Language Models**
(2021.06.25) [[pdf]](https://arxiv.org/abs/2106.13884) ![](https://img.shields.io/badge/-NIPS%202021-lightgrey) ![](https://img.shields.io/badge/-classic-red) <br> 

#### CoT in vision
- **Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings**
(2023.05.03) [[pdf]](https://arxiv.org/abs/2305.02317)

- **Chain of Thought Prompt Tuning in Vision Language Models**
(2023.04.16) [[pdf]](https://arxiv.org/abs/2304.07919)


### Theoretical analysis
- **What In-Context Learning "Learns" In-Context: Disentangling Task Recognition and Task Learning** 
(2023.05.16) [[pdf]](https://arxiv.org/abs/2305.09731) <br> 

- **Symbol tuning improves in-context learning in language models** 
(2023.05.15) [[pdf]](https://arxiv.org/abs/2305.08298) <br>

- **Larger language models do in-context learning differently** 
(2023.03.07) [[pdf]](https://arxiv.org/abs/2303.03846) <br> 

- **Meta Learning to Bridge Vision and Language Models for Multimodal Few-Shot Learning** 
(2023.02.28) [[pdf]](https://arxiv.org/abs/2302.14794) <br> 

- **Transformers as Algorithms: Generalization and Stability in In-context Learning**
(2023.01.17) [[pdf]](https://arxiv.org/abs/2301.07067) <br>

- **Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta-Optimizers**
(2022.12.20) [[pdf]](https://arxiv.org/abs/2212.10559) <br>

- **Transformers learn in-context by gradient descent**
(2022.12.15) [[pdf]](https://arxiv.org/abs/2212.07677) <br>

- **What learning algorithm is in-context learning? Investigations with linear models**
(2022.11.28) [[pdf]](https://arxiv.org/abs/2211.15661) <br>

- **In-context Learning and Induction Heads** 
(2022.09.24) [[pdf]](https://arxiv.org/abs/2209.11895) <br> 

- **Data Distributional Properties Drive Emergent In-Context Learning in Transformers** 
(2022.04.22) [[pdf]](https://arxiv.org/abs/2205.05055) <br> 

- **An Explanation of In-context Learning as Implicit Bayesian Inference** 
(2021.11.03) [[pdf]](https://arxiv.org/abs/2111.02080)  ![](https://img.shields.io/badge/-classic-red) <br> 

### Chain of thoughts

- **Active Prompting with Chain-of-Thought for Large Language Models**
(2023.02.23) [[pdf]](https://arxiv.org/abs/2302.12246)

- **Faithful Chain-of-Thought Reasoning**
(2023.01.31) [[pdf]](https://arxiv.org/abs/2301.13379)

- **Automatic Chain of Thought Prompting in Large Language Models**
(2022.10.07) [[pdf]](https://arxiv.org/abs/2210.03493)

- **Large Language Models are Zero-Shot Reasoners**
(2022.05.24) [[pdf]](https://arxiv.org/abs/2205.11916) ![](https://img.shields.io/badge/-classic-red)

- **Self-Consistency Improves Chain of Thought Reasoning in Language Models**
(2022.03.21) [[pdf]](https://arxiv.org/abs/2203.11171) ![](https://img.shields.io/badge/-classic-red)

- **Chain-of-Thought Prompting Elicits Reasoning in Large Language Models**
(2022.01.28) [[pdf]](https://arxiv.org/abs/2201.11903) ![](https://img.shields.io/badge/-classic-red) <br> 


#### Theoretical analysis of CoT
- **Large Language Models Can Be Easily Distracted by Irrelevant Context**
(2023.01.23) [[pdf]](https://arxiv.org/abs/2302.00093)

- **Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters**
(2022.12.20) [[pdf]](https://arxiv.org/abs/2212.10001)

- **Large Language Models are Better Reasoners with Self-Verification**
(2022.12.19) [[pdf]](https://arxiv.org/abs/2212.09561)

## Contribution
If you think there are still papers worth reading, other useful resources, feel free to contribute!

